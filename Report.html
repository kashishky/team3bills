<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Team 3">
<meta name="dcterms.date" content="2025-02-19">

<title>Congressional Bills Data Project Report</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="Report_files/libs/clipboard/clipboard.min.js"></script>
<script src="Report_files/libs/quarto-html/quarto.js"></script>
<script src="Report_files/libs/quarto-html/popper.min.js"></script>
<script src="Report_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="Report_files/libs/quarto-html/anchor.min.js"></script>
<link href="Report_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="Report_files/libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="Report_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="Report_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="Report_files/libs/bootstrap/bootstrap-8a79a254b8e706d3c925cde0a310d4f0.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">


</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Congressional Bills Data Project Report</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Team 3 </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">February 19, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="introduction-and-dataset-overview" class="level1">
<h1>Introduction and Dataset Overview</h1>
<p>This report presents an extensive, step-by-step account of how our team gathered and analyzed legislative data from the 118th session of the U.S. Congress. The principal objective was to collect detailed attributes about congressional bills—sponsors, cosponsors, committees, subject categories, and voting outcomes—and transform them into a robust, structured dataset suitable for advanced analysis.</p>
<p>The core dataset consists of hundreds of bills, reflecting a wide range of legislative activity. It merges textual information (bill titles, sponsor names, status descriptions) with numeric or date-based elements (number of cosponsors, date of introduction, vote outcomes). A key challenge is dealing with the abundance of categorical data (e.g., sponsor names, committees, status labels, subject tags). Our methodology addressed this through comprehensive cleaning, transformation, and feature engineering techniques.</p>
<hr>
</section>
<section id="data-acquisition-methodology" class="level1">
<h1>Data Acquisition Methodology</h1>
<p>We first acquired the raw data using BeautifulSoup that targeted <strong>GovTrack</strong>, a public website tracking legislation. This script systematically iterates through possible bill identifiers (for example, “hr10” or “sres5”) and checks if a bill webpage is valid. If it is, the script retrieves the HTML content and extracts from the pages of the bold sections:</p>
<ul>
<li><strong>Overview Elements</strong>: Bill title, a brief summary, sponsor information, and a textual field showing how many cosponsors or cosponsor remarks were given.<br>
</li>
<li><strong>Detail Elements</strong>: Committees assigned, recorded votes (if any), related bills, and subject areas.<br>
</li>
<li><strong>Cosponsor Lists</strong>: In some cases, there is a complete listing of cosponsors, which we transform into a single string or further processed for cosponsor counts.</li>
</ul>
<p>The resulting output from this scraping step is a CSV file containing raw legislative data. Because different bill types (House bills, Senate bills, joint resolutions, standard resolutions, etc.) can appear in varying states (introduced, referred, passed, or never acted upon), the dataset includes many partial or missing fields—particularly for bills that did not move past the introduction phase. This variability underscores the complexity of real-world legislative data.</p>
<p>In capturing this broad range of bills, we ensured a sufficiently large dataset covering multiple committees, a wide variety of sponsors, and subject tags from key legislative domains. However, many bills never progress far enough to accumulate cosponsors or reach a floor vote, leading to numerous missing or inconsistent fields, requiring a thorough cleaning process next.</p>
<hr>
</section>
<section id="cleaning-and-preprocessing-steps" class="level1">
<h1>Cleaning and Preprocessing Steps</h1>
<p>Three separate scripts or notebooks originally handled our cleaning, transformation, and partial exploration tasks. We combined their logic into a single overarching workflow to produce a consolidated dataset:</p>
<ol type="1">
<li><strong>Initial Data Loading and Basic Fixes</strong>
<ul>
<li>We read the raw scraped CSV. Because many text fields, such as “Vote Result,” “Status,” and “Subjects,” contain multiple pieces of information, the data needed to be parsed carefully. For instance, the <code>Status</code> column might include both a short descriptor and a date in parentheses. We extracted those components into two separate columns: one for a cleaned status (like “Introduced” or “Failed”) and one for a status date where it existed.<br>
</li>
<li>Date fields (like <code>Introduced</code> or <code>Vote Date</code>) appear in inconsistent text formats. We converted them into a standardized date format to facilitate timeline calculations and comparisons.</li>
</ul></li>
<li><strong>Managing Missing Values and Anomalies</strong>
<ul>
<li>Numerous bills lacked cosponsor data if they never garnered any cosponsors. We allowed for a “0 cosponsors” logic, while also creating a binary indicator (<code>Has Cosponsors</code>) for bills with at least one cosponsor.<br>
</li>
<li>In some cases, text-based fields inadvertently contained date strings or partially corrupted references. For example, the <code>Vote Result</code> column might have an actual date. The code replaced these anomalies by shifting the date to the <code>Vote Date</code> column and setting the <code>Vote Result</code> to a standardized placeholder.</li>
</ul></li>
<li><strong>One-Hot Encoding and Expansion of Categorical Features</strong>
<ul>
<li>The “Subjects” column, if populated, might list multiple topics for each bill (e.g., “Taxation, Public Lands”). We separated each topic into its own binary indicator column. This drastically expanded the dataset’s width, creating many sparse columns.<br>
</li>
<li>Sponsor and Committee fields, which are also categorical, were label-encoded in the final step (though we could have used one-hot encoding, label encoding (in our EDA jupyter notebook) was chosen to keep the dataset size manageable and to support correlation or tree-based analysis more directly).</li>
</ul></li>
<li><strong>Reducing Near-Zero Variance Predictors</strong>
<ul>
<li>Because we ended up with a substantial number of columns (particularly from subjects), certain columns displayed no variation (all zeros or nearly all zeros). Using a variance threshold, we automatically dropped columns that contributed no useful information, adhering to best practices from the lectures regarding zero or near-zero variance features.</li>
</ul></li>
<li><strong>K-Nearest Neighbors (KNN) Imputation</strong>
<ul>
<li>For numeric fields that remained incomplete after the above cleaning steps, we employed KNN-based imputation. This approach helped ensure the missing values were imputed in a way that used similarities across multiple attributes, rather than relying on a global mean or median. Also for the ‘object’ columns we used mode to perform the imputation as this was categorical fields noted in Lecture 2. However, we recognize that imputing these columns is not necessarily conducive towards a formal analysis considering the subject matter of our dataset. Regardless, this was appropriate for the conditions of this assignment.</li>
</ul></li>
</ol>
<p>By the end of this process, we produced a well-structured file, <strong><code>final_congress_bills_data.csv</code></strong>, containing carefully curated columns for bills, sponsors, committees, vote data, cosponsors, and subject tags. The main rationale for each step was to standardize the variety of textual and numeric anomalies in the source data, reduce unhelpful columns, and create consistent, model-friendly features.</p>
<hr>
</section>
<section id="exploratory-data-analysis-eda" class="level1">
<h1>Exploratory Data Analysis (EDA)</h1>
<p>With a cleaned and feature-rich dataset, we turned to in-depth EDA in a separate notebook. This analysis aimed to uncover patterns in legislative sponsorship, committee activity, cosponsorship behavior, and ultimate bill outcomes.</p>
<ol type="1">
<li><strong>Initial Descriptive Statistics</strong>
<ul>
<li>We examined how many bills exist post-cleaning, how many numeric vs.&nbsp;categorical columns remain, and how often certain fields are missing. This step confirmed that bills without a floor vote remain common, reflecting typical legislative dynamics where many introductions never proceed to a recorded vote.</li>
</ul></li>
<li><strong>Sponsor and Committee Distributions</strong>
<ul>
<li>We observed that a small group of sponsors introduced the majority of bills. This finding is consistent with real-world legislative behavior, where a few motivated or high-profile lawmakers sponsor numerous pieces of legislation.<br>
</li>
<li>Certain committees, such as Appropriations or Judiciary, had notably high activity. This concentration hints at subject areas or procedural roles that funnel many bills through specific committees.</li>
</ul></li>
<li><strong>Vote Timelines</strong>
<ul>
<li>Using the introduced and vote dates (where available), we calculated how long each bill took to progress to a vote. A histogram of these durations revealed a wide variance, with some bills moving quickly (within days) and many never receiving a vote at all.</li>
</ul></li>
<li><strong>Vote Results and Differences</strong>
<ul>
<li>Bills that did receive a recorded vote often displayed a relatively narrow vote margin, though we also spotted some landslide outcomes. Meanwhile, many bills were labeled “No Result,” indicating they did not get a final floor vote.<br>
</li>
<li>Analyzing the distribution of cosponsor counts showed that bills with higher cosponsor engagement correlated loosely with success, although causation cannot be definitively established from this alone.</li>
</ul></li>
<li><strong>Subject Category Prevalence</strong>
<ul>
<li>After the extensive encoding, we identified which policy areas or subjects occurred most frequently. A handful of broad topics dominated. This step underscored the legislative focus areas in the dataset.</li>
</ul></li>
</ol>
<p>Overall, our EDA highlighted the imbalances of the legislative process, confirming that sponsor “hyperactivity,” committee bottlenecks, and the presence or absence of cosponsors can shape a bill’s trajectory. The necessity of advanced transformations (like label encoding and missing data imputation) became evident, as did the difficulty in deriving conclusive trends from partial or skewed data.</p>
<hr>
</section>
<section id="feature-engineering-methods-and-rationale" class="level1">
<h1>Feature Engineering: Methods and Rationale</h1>
<p>Beyond the fundamental cleaning and EDA, we pursued more advanced feature engineering to capture deeper structure in the data:</p>
<ol type="1">
<li><strong>Correlation Plots</strong>
<ul>
<li>After finalizing the cleaned numerical features, we created correlation matrices to spot highly correlated pairs of variables. This was visualized as a heatmap, allowing us to see at a glance if any columns—such as cosponsor count and time-to-vote—were overly correlated. Strong correlations inform decisions about which features to keep, drop, or combine. For instance, if several subject-related variables are essentially duplicates, a correlation heatmap can help identify redundancy before modeling.</li>
</ul></li>
<li><strong>Principal Component Analysis (PCA)</strong>
<ul>
<li>Given the sheer volume of subject-based columns and other one-hot expansions, our dataset risked becoming unwieldy. PCA helps reduce dimensionality by identifying underlying principal components that explain most variance in the data.<br>
</li>
<li>This is crucial to mitigate the impact of correlated or near-duplicate columns—an inevitable situation when dealing with tens or hundreds of subject indicators.</li>
</ul></li>
<li><strong>Polynomial Features</strong>
<ul>
<li>In pursuit of capturing potential nonlinear relationships, we tested generating interaction terms and squared terms for Time to Vote and Cosponsor Count. This might help uncover more complex patterns with regards to their level of correlation across subject areas.<br>
</li>
<li>However, polynomial expansions can dramatically increase the feature space, so we combined them with PCA to keep the final representation tractable (see code prior to correlation plots).</li>
</ul></li>
<li><strong>Clustering (K-Means) on PCA Outputs</strong>
<ul>
<li>As an exploratory step, we used unsupervised clustering to see if certain types of bills naturally group together along lines of sponsor ideology, subject matter, or committees. By applying K-Means to the reduced PCA dimensions, we can identify possible “clusters” of bills.<br>
</li>
<li>After forming clusters, we can investigate which committees or sponsors frequently appeared in each group. This approach can yield insights into legislative “themes”—for instance, a cluster dominated by defense-related topics or a cluster with bipartisan cosponsorship patterns.</li>
</ul></li>
<li><strong>Binary Encoding of Vote Outcomes</strong>
<ul>
<li>Another form of feature engineering involved simplifying vote outcomes (e.g., “Passed,” “Failed,” or “No Result”) into a single numeric label or target variable for classification tasks. This is vital if we want to train predictive models to guess a bill’s success based on its attributes.<br>
</li>
<li>Additionally, we computed a “Vote Difference” feature—essentially (yes votes – no votes)—for bills that did have a final vote. This numeric difference can help capture how contentious or supported a particular measure was.</li>
</ul></li>
</ol>
<p>Each step was deliberate, addressing:</p>
<ul>
<li><strong>High Dimensionality</strong> (using correlation plots followed by PCA).<br>
</li>
<li><strong>Potential Nonlinear Relationships</strong> (using polynomial expansions).<br>
</li>
<li><strong>Patterns in Categorical Dominance</strong> (using K-Means clusters or label-encoded outcomes).</li>
</ul>
<p>Though the assignment rubric didn’t explicitly require predictive modeling, these advanced transformations open the door to logistic regression, tree-based models, or other predictive frameworks in future work.</p>
<hr>
</section>
<section id="summary-of-key-findings" class="level1">
<h1>Summary of Key Findings</h1>
<p>Through data cleaning, exploration, and feature engineering, we uncovered several important themes:</p>
<ol type="1">
<li><p>A significant subset never progresses beyond introduction or committee referral, illuminating a reality of the legislative process rather than just data quality issues.</p></li>
<li><p>A minor fraction of legislators introduce the bulk of bills, possibly reflecting leadership roles or particularly engaged lawmakers.</p></li>
<li><p>Key committees—particularly those with broad jurisdiction—surface again and again, hinting at central legislative “choke points.”</p></li>
<li><p>Bills with many cosponsors exhibit somewhat higher success rates, consistent with the idea that broader support fosters legislative momentum.</p></li>
<li><p>While the one-hot encoding of subjects created many columns, the top few subjects repeatedly dominated the dataset, suggesting recurring policy focus areas in this congressional session.</p></li>
<li><p>Preliminary unsupervised exploration indicated some grouping of bills by subject matter or sponsor styles. Detailed cluster analysis could refine these findings further.</p></li>
</ol>
<p>These insights emerged only after careful data transformations and EDA. The shortfalls—such as incomplete votes and the large number of “No Result” statuses—are part of genuine legislative constraints, not just flaws in data handling.</p>
<hr>
</section>
<section id="challenges-and-future-recommendations" class="level1">
<h1>Challenges and Future Recommendations</h1>
<section id="challenges" class="level2">
<h2 class="anchored" data-anchor-id="challenges">Challenges</h2>
<ol type="1">
<li><p><strong>Inherent Data Gaps</strong><br>
The legislative process naturally leaves many bills without final votes or extensive cosponsor data, complicating attempts at a universal analysis of “success.”</p></li>
<li><p><strong>Categorical Explosion</strong><br>
Incorporating all subject tags led to substantial dimensional expansion. This made techniques like PCA essential to avoid unwieldy data frames.</p></li>
<li><p><strong>Site Dependency</strong><br>
The scraping process depends on a stable site structure. If GovTrack changes page layouts or HTML tags, future runs may break.</p></li>
</ol>
</section>
<section id="future-directions" class="level2">
<h2 class="anchored" data-anchor-id="future-directions">Future Directions</h2>
<ol type="1">
<li><p><strong>API Integration</strong><br>
If GovTrack or another platform provides an official API, hooking into that might yield more stable, structured data with fewer missing values.</p></li>
<li><p><strong>Predictive Modeling</strong><br>
With the dataset preprocessed, we can attempt logistic regression, gradient boosting, or random forests on the question: “Does this bill pass or fail?” We would consider sponsor features, committees, and cosponsor counts as potential predictors.</p></li>
<li><p><strong>Temporal/Historical Comparisons</strong><br>
Scraping older sessions of Congress could allow time-series or comparative analysis, showing how legislative focus areas shift from session to session.</p></li>
</ol>
<p>Overall, these recommendations flow naturally from the challenges identified. Despite the complexities, our dataset is now robust enough for various extended analyses.</p>
<hr>
</section>
<section id="github" class="level2">
<h2 class="anchored" data-anchor-id="github">Github</h2>
<p>The GitHub repsoitory has been shared directly with Professor Pijyan and is Public under <a href="https://github.com/kashishky/team3bills" class="uri">https://github.com/kashishky/team3bills</a>.</p>
<hr>
</section>
<section id="member-contributions" class="level2">
<h2 class="anchored" data-anchor-id="member-contributions">Member Contributions</h2>
<section id="all-members-contributed-according-to-our-pre-arrangement." class="level4">
<h4 class="anchored" data-anchor-id="all-members-contributed-according-to-our-pre-arrangement.">All members contributed according to our pre-arrangement.</h4>
<ul>
<li>Kashish Kumar: Scraping, EDA/Feature Engineering, GitHub management</li>
<li>Yinhan Wang: EDA/Feature Engineering, GitHub Management</li>
<li>Hanzhong Yang: Missingness, Imputation, Outliers</li>
<li>Ran Yan: Preprocessing, Variance Thresholding</li>
</ul>
</section>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>